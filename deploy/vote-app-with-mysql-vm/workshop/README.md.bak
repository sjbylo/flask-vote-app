# WORK IN PROGRESS

# Worklshoip - Mixed Pod + VM OpenShift Virtualization GitOps demo

Use OpenShift Virtualization & GitOps to deploy a demo vote application pod and a MySQL VM (running either RHEL or Centos-Stream).

You can learn more about GitOps from this [GitOps Workshop Guide](https://openshiftdemos.github.io/openshift-gitops-workshop/openshift-gitops-workshop/index.html).


<img src="./images/vote-app-plus-vm-demo.png" alt="This is what it looks like" width="500">


We will use OpenShift GitOps Opertator (based on ArgoCD project) to implement GitOps and deploy our demo application. 

First, you will provision an instance of ArgoCD into your OpenShift namespace which you can use for yourself.  

Add the following ArgoCD resource into your namepace.  There are many ways to do this, e.g. via the OpenShift Console or via the command line.

Don't forget to change the `YOUR-OPENSHIFT-NAMESPACE` to your OpenShift namepace. 

```
apiVersion: argoproj.io/v1beta1
kind: ArgoCD
metadata:
  name: YOUR-OPENSHIFT-NAMESPACE
  namespace: YOUR-OPENSHIFT-NAMESPACE
spec:
  controller:
    processors: {}
    resources:
      limits:
        cpu: "2"
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 1Gi
    sharding: {}
  grafana:
    enabled: false
    ingress:
      enabled: false
    route:
      enabled: false
  ha:
    enabled: false
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi
  initialSSHKnownHosts: {}
  monitoring:
    enabled: false
  notifications:
    enabled: false
  prometheus:
    enabled: false
    ingress:
      enabled: false
    route:
      enabled: false
  rbac:
    defaultPolicy: ""
    policy: |
      g, system:authenticated, role:admin
      g, system:cluster-admins, role:admin
    scopes: '[groups, users]'
  redis:
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 250m
        memory: 128Mi
  repo:
    resources:
      limits:
        cpu: "1"
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 256Mi
  resourceExclusions: "- apiGroups:\n  - tekton.dev\n  clusters:\n  - '*'\n  kinds:\n
    \ - TaskRun\n  - PipelineRun        \n"
  server:
    autoscale:
      enabled: false
    grpc:
      ingress:
        enabled: false
    ingress:
      enabled: false
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 125m
        memory: 128Mi
    route:
      enabled: true
    service:
      type: ""
  sso:
    dex:
      openShiftOAuth: true
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 250m
          memory: 128Mi
    provider: dex
  tls:
    ca: {}
```

Wait 5 mins for all the pods in your namepace to be Running and Ready (1/1). 

Find the Route that was created and access it to open the ArgoCD UI at the login page.
Log into ArgoCD with your usual OpenShift credentials and, on the next page, allow the `access permissions`.

Here is one way to find the ArgoCD Route.  The other way is to look at the main menu on the left under Networking -> Routes. 

```
oc get route -n USER_PLACEHOLDER-argocd USER_PLACEHOLDER-argo-server -o jsonpath='{.spec.host}{"\n"}'
```

You will now see the ArgoCD UI. 

Create the vote-app Application using the following Application resource. Note, this will onlt work for clusters with direct access to the Internet. 

```
kind: Application
metadata:
  name: vote-app-mixed
  namespace: YOUR-OPENSHIFT-NAMESPACE
spec:
  destination:
    namespace: YOUR-OPENSHIFT-NAMESPACE
    server: https://kubernetes.default.svc
  project: default
  source:
    path: deploy/vote-app-with-mysql-vm/direct
    repoURL: https://github.com/sjbylo/flask-vote-app.git
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
      selfHeal: false
```

- `destionation`: describes into which cluster and namespace to apply the yaml resources (using the locally-resolveable URL for the cluster)
- `project default`: is an ArgoCD concept and has nothing to do with any OpenShift peojects
- `source`: describes from which git repository and the directory path to fetch the yaml resources
- `prune`: resources, that have been removed from the Git repo, will be automatically pruned
- `selfHeal` false: manual changes made to the kubernetss resources, e.g. using oc or kubectl, will not be "healed"

Note that after the VM status is `Running` it will still `take up to 5 mins` for the MySQL VM to launch and run its `cloud-init` script to install, configure and run MySQL, 
after which the vote application will connect to the database and be ready to use.  

Log into the MySQL VM's Console and check out how the cloud-init script was executed.  See the log file at /var/log/cloud-init-output.log.

Also, verify that mysql is running in the VM with "ps -ef | grep -i mysql".  Optional, connect to MySQL and view the database contents.


## Self healing

Notice that we set the following in the above yaml resource.  We set the applicaiton to NOT self heal.  Let's test this now. 

```
spec:
  syncPolicy:
    automated:
      prune: true
      selfHeal: false 
```

Since `selfHeal` was set to false, we will delete one of the kubernetes resources of the application.

Now, delete the vote-app route in your namespace. 

What happenes? 

It does not get re-created automatically!   

Set selfHeal to "auto" in the ArgoCD UI.  Go to the Applicaiton, click `Details` and make the change for the vote-app to self heal. 
Save the changes.   

Make a change in OpenShift and see it "heal":

